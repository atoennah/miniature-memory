# miniature-memory

A minimal, memory-aware dataset and training pipeline for small GPT-style models, focused on adult entertainment.

## About This Project

`miniature-memory` is a from-scratch NanoGPT implementation designed to run on low-RAM (~2GB) environments. It includes a full pipeline for scraping, cleaning, and training on a continuously growing dataset of adult narrative text.

**This project is explicitly for adult entertainment.** Please see the `CONTRIBUTING.md` for a full statement of purpose.

## Key Goals

- **Constraint-First:** Build a model that is effective and coherent under extreme hardware limitations.
- **Automation:** The entire data pipeline is designed to be automated and reproducible.
- **Adult Narrative:** The model is trained exclusively on adult stories to generate high-quality erotic fiction.

## Getting Started

For detailed technical information, including setup, repository structure, and training workflows, please see the **[DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md)**.

## Project Status

This project is under active development. You can follow the development plan in the [ROADMAP.md](ROADMAP.md).
